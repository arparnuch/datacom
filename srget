#!/usr/bin/env python

import socket as sk 
import os
import sys
from urlparse import urlparse

def mkDownloadRequest(serv, objNmae):
	return ("GET {o} HTTP/1.1\r\n" + "Host: {s}" + "\r\n\r\n").format(o=objNmae, s=serv)

def mkRangeRequest(serv, objNmae, byte):
	print "Enter byte range request"
	return ("GET {o} HTTP/1.1\r\n" + "Host: {s}\r\n" + "Range: bytes={b}-\r\n\r\n").format(o=objNmae, s=serv, b=byte)

def getheader(data): ## index is the index of \r\n\r\n ## if the web does not have header this function is DOOMED
	text = ""
	text = text + data
	header = ""
	found_index = text.find('\r\n\r\n')
	header_length = found_index+4
	if found_index != -1: ## found \r\n\r\n
		header = data[:found_index]
	
	piece = data[header_length:]
	

	if not os.path.exists('./header.txt'): # if not exisit create file
		f3 = open('./header.txt', "w")  ## This here was "wb"
	with open('header.txt', "w") as f: ## This here was "wb"
		f.write(header)

	return (header, piece)
def getsizefile(filepath):
	return os.path.getsize(filepath)
	

def getDateModified(filename):
 ## it suppose to be header
 	count = 0
 	date_modified = ""
 	location = "./" + filename
	with open(location, "r") as f:
		header = f.read()
		last_modified_index = header.find("Last-Modified")
		
		if last_modified_index != -1:
			enter_index = header[last_modified_index:].find('\r\n')
			date_modified = header[last_modified_index:last_modified_index+enter_index]

			
		# print header[last_modified_index:]
		

def getcontenlength(header): ## get header file
	count = 0
	enter_index = 0
	content_length_index = header.find('Content-Length')
	# print content_length_index
	content_length = 0

	if content_length_index != -1:
		enter_index = header[content_length_index:].find('\r\n')
		content_length = header[content_length_index:content_length_index + enter_index].split(':')[1][1:]
		# print content_length

	return int(content_length)



def download_file(sock__, filename):
	count = 0
	header = ""
	body = ""
	body_length = 0
	header_info = None
	piece = ""
	content_length = 0
	location = "./" + filename
	while True:
		data = sock__.recv(1024)
		# print data
		enter2_index = data.find('\r\n\r\n')

		if enter2_index != -1: ## foudn \r\n\r\n
			count += 1
			print "count" + str(count)


		if count == 1:
			count += 1
			header_info = getheader(data)
			header = header_info[0] ## correct
			piece = header_info[1]
			content_length = getcontenlength(header)
			body_length += len(piece)
			with open(filename, "a+") as f1:
				f1.write(piece)
				f1.flush()
			
		elif body_length < content_length:
			body_length += len(data)
			with open(filename, "a+") as f2:
				f2.write(data)
				f2.flush()
			
		elif body_length == content_length:
			with open(filename, "a+") as f3:
				f3.write(body)
				f3.flush()
			print content_length
			print body_length
			sock__.close()
			break

def resume(filename, sock__):
	location = "./" + filename

	enter2_index = 0
	count = 0
	header = ""
	body = ""
	body_length = 0
	header_info = None
	piece = ""
	content_length = 0

	
	while True:
		data = sock__.recv(1024)
		enter2_index = data.find('\r\n\r\n')
		
		if enter2_index != -1: ## foudn \r\n\r\n
			count += 1
			print "count" + str(count)


		if count == 1:
			count += 1
			header_info = getheader(data)
			header = header_info[0] ## correct
			
			piece = header_info[1]
			content_length = getcontenlength(header)
			
			body_length += len(piece)
			with open(filename, "a+") as f1:
				f1.write(piece)
				f1.flush()

		elif body_length < content_length:
			
			body_length += len(data)
			print "Body length + data: " + str(body_length)
			with open(filename, "a+") as f2:
				f2.write(data)
				f2.flush() ## why after download to the right amount of data it just wait for like 
	
		if body_length == content_length:
			print "Not Enter"
			with open(filename, "a+") as f3:
				f3.write(body)
				f3.flush()
			print content_length
			print body_length
			sock__.close()
			break

def getConnetion(parsed_url,filename, downloaded_size):
	
	scheme = parsed_url[0]
	servName = parsed_url[1]   #'www.google.co.th'
	path = parsed_url[2]
	port = parsed_url.port

	if scheme == 'http':
		pass
	else:
		sys.exit(2) ## when you want to die enter any number except 0 welcome!!

	if port == None:
		port = 80

	
	sock = sk.socket(sk.AF_INET, sk.SOCK_STREAM)

		
	if downloaded_size == 0:
		print "Enter downloaded_size == 0"
		request = mkDownloadRequest(servName, path)	
	else:
		request = mkRangeRequest(servName, path, downloaded_size)

	sock.connect((servName, port))
	sock.send(request)

	return sock			
		
def srget():
	## IF HTTPS PRINT THIS WEB IS SECURE AND SOCK.CLOSE 
	# sys.exit

	# len(sys.argv) = # of args
	arg_list = sys.argv

	filename = arg_list[2]

	url = arg_list[3]
	result = urlparse(url)
	

	
	
	# location = "./" + filename
	print filename
	if os.path.exists(filename): ## if exist create file -- > resume
		print "enter"
		downled_size = os.path.getsize(filename)
		print "downled_size : " + str(downled_size)	

		sock = getConnetion(result, filename, downled_size)
		resume(filename, sock)

	else:  ## load all
		print "enter2"
		sock = getConnetion(result,filename, 0)
		download_file(sock, filename)



	


srget()

# srget -o test.txt http://www.google.com/

## if download --> interrupt --> don't crash save only we got

## if filename already exist in the folder --> if not download as normal
				# ||
## first if you want to resume
	## check first if the file modified date is changed or not 
		## if it is --> redownload the whole file
		## if not --> check size of file to compare with the content-length  --> request for byte that we want
		








