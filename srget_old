#!/usr/bin/env python

import socket as sk 
import os
import sys
from urlparse import urlparse

	
def mkRangeRequest(serv, objNmae, byte):
	# print "Enter byte range request"
	return ("GET {o} HTTP/1.1\r\n" + "Host: {s}\r\n" + "Range: bytes={b}-\r\n\r\n").format(o=objNmae, s=serv, b=byte)

def getHeaderRequest(serv, objNmae):
	return ("HEAD {o} HTTP/1.1\r\n" + "Host: {s}" + "\r\n\r\n").format(o=objNmae, s=serv)

def getHeader_Before(arg_list):
	filename = arg_list[2] 
	url = arg_list[3] 
	result = urlparse(url) 
	
	scheme = result[0]
	servName = result[1]   #'www.google.co.th'
	path = result[2]
	port = result.port

	if scheme == 'http':
		pass
	else:
		print "Unable to download from this file"
		sys.exit(2) ## when you want to die enter any number except 0 welcome!!

	if port == None:
		port = 80

	sock = sk.socket(sk.AF_INET, sk.SOCK_STREAM)		
	request = getHeaderRequest(servName, path)	
	
	sock.connect((servName, port))
	sock.send(request)

	while True:
		data = sock.recv(1024)
		# print data
		with open('before_header.txt', "w") as f:
			f.write(data)
		if data.find('\r\n\r\n') != -1:
			break
			
def getheader(data , saved_filename): ## index is the index of \r\n\r\n ## if the web does not have header this function is DOOMED
	text = ""
	text = text + data
	header = ""
	found_index = text.find('\r\n\r\n')
	header_length = found_index+4
	if found_index != -1: ## found \r\n\r\n
		header = data[:found_index]
	
	piece = data[header_length:]
	
	if saved_filename != None:
		f3 = open(saved_filename, "w") # override it ## This here was "wb"
		with open(saved_filename, "w") as f: ## This here was "wb"
			f.write(header)

	return (header, piece)

def getSomething(filename, something): ## version include getDateModified and getETag
	count = 0
 	date_modified = ""
 	location = "./" + filename
	with open(location, "r") as f:
		header = f.read()
		found_sth_index = header.find(something)
	
	if found_sth_index != -1:
		enter_index = header[found_sth_index:].find('\r\n')
		result = header[found_sth_index:found_sth_index+enter_index]
		return result
	else:
		return None

def getcontenlength(header): ## get header file
	count = 0
	enter_index = 0
	content_length_index = header.find('Content-Length')
	# print content_length_index
	content_length = 0

	if content_length_index != -1:
		enter_index = header[content_length_index:].find('\r\n')
		content_length = header[content_length_index:content_length_index + enter_index].split(':')[1][1:]
		# print content_length

	return int(content_length)
		


def checkResumable(oldfile, newfile, downloaded_size): ## check date  -- > check downloaded size vs Contenlength

	old_ETag = getSomething(oldfile, "ETag")
	new_ETag = getSomething(newfile, "ETag")

	boo1 = True
	boo2 = True
	boo3 = True
	content_length = 0


	# check Etag first and then date modified

	if old_ETag == None: ## don't have ETaf
		old_date = getSomething(oldfile, "Last-Modified")
		new_date = getSomething(newfile, "Last-Modified")

		if old_date != new_date: ## different file
			boo1 = False
		
	elif old_ETag != new_ETag: ## have ETag + same file
		boo3 = False

	with open(oldfile, "r") as f1:
		header = f1.read()
		content_length = getcontenlength(header) # get content-length from old file

	if downloaded_size < content_length: ## unfinished download
		boo2 = True
	else:
		boo2 = False

	check = (boo1 and boo2) or (boo2 and boo3)
	print "Your file already exist"
	return check


def download_file(sock__, filename):
	count = 0
	header = ""
	body = ""
	body_length = 0
	header_info = None
	piece = ""
	content_length = 0
	location = "./" + filename
	while True:
		data = sock__.recv(1024)
		# print data
		enter2_index = data.find('\r\n\r\n')

		if enter2_index != -1: ## foudn \r\n\r\n
			count += 1
			print "count" + str(count)


		if count == 1:
			count += 1
			header_info = getheader(data, 'old_header.txt')
			print "Write old header"
			header = header_info[0] ## correct
			piece = header_info[1]
			content_length = getcontenlength(header)
			body_length += len(piece)
			with open(filename, "a+") as f1: ## write in file
				f1.write(piece)
				f1.flush()
			
		elif body_length < content_length:
			body_length += len(data)
			with open(filename, "a+") as f2:
				f2.write(data)
				f2.flush()
			
		# elif body_length == content_length:
		# 	with open(filename, "a+") as f3:
		# 		f3.write(body)
		# 		f3.flush()
		# 	print content_length
		# 	print body_length
		# 	sock__.close()
		# 	break

def resume(filename, sock__):
	location = "./" + filename
	enter2_index = 0
	count = 0
	header = ""
	body = ""
	body_length = 0
	header_info = None
	piece = ""
	content_length = 0

	
	while True:
		data = sock__.recv(1024)
		enter2_index = data.find('\r\n\r\n')
		
		if enter2_index != -1: ## foudn \r\n\r\n
			count += 1
			print "count" + str(count)


		if count == 1:
			count += 1
			header_info = getheader(data, None)
			# print "Write new header"
			header = header_info[0] ## correct
			
			piece = header_info[1]
			content_length = getcontenlength(header)
			
			body_length += len(piece)
			with open(filename, "a+") as f1:
				f1.write(piece)
				f1.flush()

		elif body_length < content_length:
			
			body_length += len(data)
			print "Body length + data: " + str(body_length)
			with open(filename, "a+") as f2:
				f2.write(data)
				f2.flush() ## why after download to the right amount of data it just wait for like 
	
		# if body_length == content_length:
		# 	print "Not Enter"
		# 	with open(filename, "a+") as f3:
		# 		f3.write(body)
		# 		f3.flush()
		# 	print content_length
		# 	print body_length
		# 	sock__.close()
		# 	break

def getConnetion(parsed_url,filename, downloaded_size):
	scheme = parsed_url[0]
	print scheme
	servName = parsed_url[1]   #'www.google.co.th'
	path = parsed_url[2]
	port = parsed_url.port
	if scheme == 'http':
		pass
	else:
		print "Unable to download from this file"
		sys.exit(2) ## when you want to die enter any number except 0 welcome!!
	if port == None:
		port = 80
	sock = sk.socket(sk.AF_INET, sk.SOCK_STREAM)		
	request = mkRangeRequest(servName, path, downloaded_size)
	sock.connect((servName, port))
	sock.send(request)

	return sock			
		
def srget():
	## IF HTTPS PRINT THIS WEB IS SECURE AND SOCK.CLOSE 
	# sys.exit
	# len(sys.argv) = # of args
	
	arg_list = sys.argv

	getHeader_Before(arg_list);
	
	filename = arg_list[2]
	url = arg_list[3]
	result = urlparse(url)
	print "Start"
	if os.path.exists(filename): ## if exist create file -- > resume
		downled_size = os.path.getsize(filename)

		print "downled_size : " + str(downled_size)	

		if checkResumable("old_header.txt", "before_header.txt", downled_size):

			sock = getConnetion(result, filename, downled_size)

			resume(filename, sock)
		print "Download Complete ....."
	else:  ## not exist -- > load all
		print "Start Downloading ....."
		sock = getConnetion(result,filename, 0)
		download_file(sock, filename)


	os.remove("old_header.txt")
	os.remove("before_header.txt")


srget()
# getETag()

## first check if file exist ?  --> date modified similar? -NO-> downloaded vs content-length equal? -NO-> if not resume it

# srget -o test.txt http://www.google.com/

## if download --> interrupt --> don't crash save only we got

## if filename already exist in the folder --> if not download as normal
				# ||
## first if you want to resume
	## check first if the file modified date is changed or not 
		## if it is --> redownload the whole file
		## if not --> check size of file to compare with the content-length  --> request for byte that we want
		








